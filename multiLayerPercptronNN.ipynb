{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "%pip install pandas matplotlib scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('malicious_phish.csv')\n",
    "\n",
    "# Display the first 5 rows to see what the data looks like\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Get a summary of the dataset (row count, column types, missing values)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check how many examples we have for each type (benign, phishing, etc.)\n",
    "print(\"\\nTarget Class Distribution:\")\n",
    "print(df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141d6df",
   "metadata": {},
   "source": [
    "## Preprocessesing\n",
    "\n",
    "For preprocessing, we will remove duplicate entries, drop fragments, and remove unnecessary whitespace to standardize the dataset. Feature extraction will focus on structural and lexical attributes including URL, domain, path, and file name segments. Numerical variables such as length-based metrics, Shannon entropy, digit counts, special character counts, and related ratios will be calculated. These features are expected to capture behavioral indicators that differentiate safe from malicious URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleaning_header",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleaning_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle Missing Values\n",
    "# Drop any rows that are missing data to ensure clean input for the model\n",
    "df = df.dropna()\n",
    "\n",
    "# 2. Remove Duplicate Records\n",
    "# Prevent the model from overfitting to repeated samples\n",
    "df = df.drop_duplicates(subset=['url'])\n",
    "\n",
    "# 3. Fragment Dropping (remove parts after #)\n",
    "# Fragments (like #section) don't affect the server-side destination and are noise\n",
    "df['url'] = df['url'].apply(lambda x: x.split('#')[0])\n",
    "\n",
    "# 4. Remove Unnecessary Whitespace\n",
    "df['url'] = df['url'].str.strip()\n",
    "\n",
    "# Display shape after cleaning\n",
    "print(f\"Shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_extraction_header",
   "metadata": {},
   "source": [
    "### Feature Extraction (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_extraction_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for Shannon Entropy\n",
    "# Shannon Entropy measures the 'randomness' of the URL string.\n",
    "# Malicious URLs often use algorithmically generated strings (high entropy)\n",
    "# while legitimate ones use readable words (lower entropy).\n",
    "def shannon_entropy(url):\n",
    "    import math\n",
    "    if not url:\n",
    "        return 0\n",
    "    entropy = 0\n",
    "    for x in set(url):\n",
    "        p_x = float(url.count(x))/len(url)\n",
    "        entropy += - p_x*math.log(p_x, 2)\n",
    "    return entropy\n",
    "\n",
    "# Helper functions to extract structural parts\n",
    "# We break the URL into its components (domain, path) to analyze them separately.\n",
    "def get_url_path(url):\n",
    "    try:\n",
    "        return urlparse(url).path\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def get_url_netloc(url):\n",
    "    try:\n",
    "        return urlparse(url).netloc\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 1. Structural Features\n",
    "# Extract the Domain (e.g., google.com) and Path (e.g., /search)\n",
    "df['domain'] = df['url'].apply(get_url_netloc)\n",
    "df['path'] = df['url'].apply(get_url_path)\n",
    "\n",
    "# 2. Length-based Features\n",
    "# Phishing URLs can be abnormally long to hide the true domain.\n",
    "df['url_length'] = df['url'].apply(len)\n",
    "df['path_length'] = df['path'].apply(len)\n",
    "df['domain_length'] = df['domain'].apply(len)\n",
    "\n",
    "# 3. Counts (digits, special symbols)\n",
    "# Malicious URLs often use IP addresses (many digits) or obfuscation characters (@, %, etc.)\n",
    "df['count_digits'] = df['url'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "df['count_special_chars'] = df['url'].apply(lambda x: sum(not c.isalnum() for c in x))\n",
    "\n",
    "# 4. Shannon Entropy\n",
    "# Calculate the randomness score defined in the helper function above.\n",
    "df['entropy'] = df['url'].apply(shannon_entropy)\n",
    "\n",
    "# 5. Ratios\n",
    "# Normalizing counts by length helps compare URLs of different sizes.\n",
    "df['digit_ratio'] = df['count_digits'] / df['url_length']\n",
    "df['special_char_ratio'] = df['count_special_chars'] / df['url_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced_features_header",
   "metadata": {},
   "source": [
    "### Feature Extraction (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "advanced_features_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction Complete. All Columns:\n",
      "Index(['url', 'type', 'domain', 'path', 'url_length', 'path_length',\n",
      "       'domain_length', 'count_digits', 'count_special_chars', 'entropy',\n",
      "       'digit_ratio', 'special_char_ratio', 'type_code', 'is_ip', 'short_url',\n",
      "       'count_dot', 'count_at', 'count_hyphen', 'count_dir',\n",
      "       'count_embed_domain'],\n",
      "      dtype='object')\n",
      "                                                 url        type  \\\n",
      "0                                   br-icloud.com.br    phishing   \n",
      "1                mp3raid.com/music/krizz_kaliko.html      benign   \n",
      "2                    bopsecrets.org/rexroth/cr/1.htm      benign   \n",
      "3  http://www.garage-pirenne.be/index.php?option=...  defacement   \n",
      "4  http://adventure-nicaragua.net/index.php?optio...  defacement   \n",
      "\n",
      "                    domain                                 path  url_length  \\\n",
      "0                                              br-icloud.com.br          16   \n",
      "1                           mp3raid.com/music/krizz_kaliko.html          35   \n",
      "2                               bopsecrets.org/rexroth/cr/1.htm          31   \n",
      "3    www.garage-pirenne.be                           /index.php          88   \n",
      "4  adventure-nicaragua.net                           /index.php         235   \n",
      "\n",
      "   path_length  domain_length  count_digits  count_special_chars   entropy  \\\n",
      "0           16              0             0                    3  3.375000   \n",
      "1           35              0             1                    5  4.079143   \n",
      "2           31              0             1                    5  3.708093   \n",
      "3           10             21             7                   18  4.660343   \n",
      "4           10             23            22                   14  5.491293   \n",
      "\n",
      "   digit_ratio  special_char_ratio  type_code  is_ip  short_url  count_dot  \\\n",
      "0     0.000000            0.187500          3      0          0          2   \n",
      "1     0.028571            0.142857          0      0          0          2   \n",
      "2     0.032258            0.161290          0      0          0          2   \n",
      "3     0.079545            0.204545          1      0          0          3   \n",
      "4     0.093617            0.059574          1      0          0          2   \n",
      "\n",
      "   count_at  count_hyphen  count_dir  count_embed_domain  \n",
      "0         0             1          0                   0  \n",
      "1         0             0          2                   0  \n",
      "2         0             0          3                   0  \n",
      "3         0             1          3                   1  \n",
      "4         0             1          3                   1  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# --- NEW HELPER FUNCTIONS ---\n",
    "\n",
    "# Check if domain is an IP address (common in malicious URLs)\n",
    "def is_ip_address(domain):\n",
    "    ip_pattern = re.compile(\n",
    "        r'^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$'\n",
    "    )\n",
    "    return 1 if ip_pattern.match(domain) else 0\n",
    "\n",
    "# Check for shortening services (bit.ly, etc)\n",
    "def is_shortening_service(url):\n",
    "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|' \n",
    "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|' \n",
    "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|' \n",
    "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|' \n",
    "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|' \n",
    "                      'tr\\.im|link\\.zip\\.net', url)\n",
    "    return 1 if match else 0\n",
    "\n",
    "# --- ADVANCED FEATURE EXTRACTION ---\n",
    "\n",
    "# 1. Suspicious Patterns\n",
    "df['is_ip'] = df['domain'].apply(is_ip_address)\n",
    "df['short_url'] = df['url'].apply(is_shortening_service)\n",
    "\n",
    "# 2. Specific Symbol Counts (often used in phishing)\n",
    "df['count_dot'] = df['url'].apply(lambda x: x.count('.'))\n",
    "df['count_at'] = df['url'].apply(lambda x: x.count('@'))\n",
    "df['count_hyphen'] = df['url'].apply(lambda x: x.count('-'))\n",
    "df['count_dir'] = df['url'].apply(lambda x: x.count('/'))\n",
    "df['count_embed_domain'] = df['url'].apply(lambda x: x.count('//'))\n",
    "\n",
    "# 3. Label Encoding for Target Variable\n",
    "le = LabelEncoder()\n",
    "df['type_code'] = le.fit_transform(df['type'])\n",
    "\n",
    "# Display the new features\n",
    "print(\"Feature Extraction Complete. All Columns:\")\n",
    "print(df.columns)\n",
    "pd.set_option('display.max_columns', None) # Ensure all columns are shown\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a72ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "training_header",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "** insert training details here (layers, activiation, input, etc) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eval_header",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Our modelâ€™s performance will be evaluated using precision, recall, accuracy, and F1 score. All of these values will be compared and visualized using a confusion matrix. Using this, the effectiveness and reliability of each model can be determined through comparison and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
